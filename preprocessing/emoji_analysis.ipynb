{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total token amount: 3077\n",
      "<URL>  ->  526859\n",
      "<3  ->  57215\n",
      ":D  ->  24443\n",
      ":P  ->  13333\n",
      ":/  ->  9655\n",
      ":')  ->  3982\n",
      "=)  ->  2595\n",
      ";D  ->  1925\n",
      "<---  ->  1768\n",
      "--->  ->  1674\n",
      ":|  ->  1504\n",
      ";P  ->  1089\n",
      "-->  ->  1022\n",
      "->  ->  992\n",
      "::  ->  739\n",
      "<--  ->  666\n",
      ":-D  ->  490\n",
      "01  ->  449\n",
      "00  ->  447\n",
      ":\\  ->  410\n",
      ":-P  ->  406\n",
      "02  ->  391\n",
      ":]  ->  386\n",
      "=D  ->  375\n",
      ":'D  ->  358\n",
      ":-/  ->  350\n",
      "0.5  ->  338\n",
      "<-  ->  336\n",
      "000  ->  297\n",
      ":@  ->  259\n",
      "07  ->  238\n",
      "09  ->  231\n",
      "05  ->  225\n",
      "03  ->  222\n",
      "=(  ->  220\n",
      "04  ->  220\n",
      "08  ->  218\n",
      "06  ->  206\n",
      ";/  ->  176\n",
      "0.0  ->  173\n",
      "=P  ->  158\n",
      "0BK  ->  156\n",
      "=/  ->  153\n",
      "001  ->  152\n",
      "=]  ->  134\n",
      "0MAH  ->  114\n",
      ":}  ->  111\n",
      "['<URL>', '<3', ':D', ':P', ':/', \":')\", '=)', ';D', '<---', '--->', ':|', ';P', '-->', '->', '::', '<--', ':-D', '01', '00', ':\\\\', ':-P', '02', ':]', '=D', \":'D\", ':-/', '0.5', '<-', '000', ':@', '07', '09', '05', '03', '=(', '04', '08', '06', ';/', '0.0', '=P', '0BK', '=/', '001', '=]', '0MAH', ':}']\n"
     ]
    }
   ],
   "source": [
    "# analyse the most frequent emojis in the training dataset\n",
    "\n",
    "import string\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# List of file names\n",
    "files = [\"../twitter-datasets/train_neg_full.txt\", \"../twitter-datasets/train_pos_full.txt\"]  # Update with your filenames\n",
    "\n",
    "# Create an empty dictionary to hold counts\n",
    "token_counts = defaultdict(int)\n",
    "\n",
    "# Define the special characters\n",
    "special_chars = \":;<-\\\\^-=0*+\"\n",
    "\n",
    "# Iterate over the files\n",
    "for filename in files:\n",
    "    \n",
    "    with open(filename, \"r\") as file:\n",
    "        # Read the file\n",
    "        data = file.read()\n",
    "        \n",
    "        # Tokenize the text file content by splitting at space\n",
    "        tokens = data.split()\n",
    "        \n",
    "        # Iterate over tokens\n",
    "        for token in tokens:\n",
    "            # Check if the length of the token is between 2 and 5\n",
    "            # and if it contains any special character\n",
    "            if 2 <= len(token) <= 5 and any(token[0] == char for char in special_chars):\n",
    "                # Increment the count of the token\n",
    "                token_counts[token] += 1\n",
    "\n",
    "# Print the dictionary\n",
    "print(f'total token amount: {len(token_counts)}')\n",
    "\n",
    "# Print the results and save the most frequent tokens into an array\n",
    "emoji_list = []\n",
    "for token, count in sorted(token_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    if count > 100:\n",
    "        print(f\"{token.upper()}  ->  {count}\")\n",
    "        emoji_list.append(token.upper())\n",
    "print(emoji_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file without emoji saved as ../twitter-datasets/train_neg_full_without_emoji.txt\n",
      "New file without emoji saved as ../twitter-datasets/train_pos_full_without_emoji.txt\n"
     ]
    }
   ],
   "source": [
    "# manuelly delete the tokens in the emoji_list that do not make sense as emojis, e.g. \"<URL>\", \"00\", \"01\"\n",
    "# map the emojis to very simple English adjectives\n",
    "# create a key: value dictionary\n",
    "\n",
    "emoji_dict = {\n",
    "    '<3': 'Lovely',\n",
    "    ':D': 'Happy',\n",
    "    ':P': 'Playful',\n",
    "    ':/': 'Unsure',\n",
    "    \":')\": 'Heartwarming',\n",
    "    '=)': 'Content',\n",
    "    ';D': 'Cheeky',\n",
    "    ':|': 'Neutral',\n",
    "    ';P': 'Teasing',\n",
    "    ':-D': 'Excited',\n",
    "    ':\\\\': 'Annoyed',\n",
    "    ':-P': 'Joking',\n",
    "    ':]': 'Happy',\n",
    "    '=D': 'Excited',\n",
    "    \":'D\": 'Delighted',\n",
    "    ':-/': 'Puzzled',\n",
    "    '=(': 'Sad',\n",
    "    ';/': 'Disappointed',\n",
    "    '0.0': 'Surprised',\n",
    "    '=P': 'Amused',\n",
    "    '=/': 'Uneasy',\n",
    "    '=]': 'Optimistic',\n",
    "    ':}': 'Smug'\n",
    "}\n",
    "\n",
    "# method for replacing the emojis with adjectives\n",
    "def replace_emoji(dictionary, text):\n",
    "    for key, value in dictionary.items():\n",
    "        text = text.replace(key.lower(), value.lower())\n",
    "    return text\n",
    "\n",
    "def get_file_without_emoji(filename):\n",
    "    output_filename = filename.replace(\".txt\", \"_without_emoji.txt\")        \n",
    "    \n",
    "    with open(filename, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "    \n",
    "    modified_lines = []\n",
    "    for line in lines:\n",
    "        line_without_emoji = replace_emoji(emoji_dict, line)\n",
    "        modified_lines.append(line_without_emoji)\n",
    "    \n",
    "    with open(output_filename, 'w') as output_file:\n",
    "        output_file.writelines(modified_lines)\n",
    "    \n",
    "    print(f\"New file without emoji saved as {output_filename}\")\n",
    "\n",
    "files = [\"../twitter-datasets/train_neg_full.txt\", \"../twitter-datasets/train_pos_full.txt\"]  # Update with your filenames\n",
    "\n",
    "for filename in files:\n",
    "    get_file_without_emoji(filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
