## No preprocessing

- batch size = 16
- learning_rate = 0.0001
- tokenizer_model = "distilbert-base-uncased"
- nn_model = "prajjwal1/bert-mini"
- binary cross entropy loss function

| Epochs | Train Accuracy | Train Accuracy |
| ------ | -------------- | -------------- |
| 2      | 0.881          | 0.871          |
| 3      | 0.890          | 0.875          |